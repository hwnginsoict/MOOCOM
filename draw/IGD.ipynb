{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nadir info not found for global_pareto_fronts_last_generation.json. Skipping.\n",
      "Detailed IGD results saved to F:/setup files/Downloads/ResultLastly/igd_pivot.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymoo.indicators.igd import IGD\n",
    "\n",
    "def calculate_igd(front, reference_pareto):\n",
    "    \"\"\"\n",
    "    Calculate IGD between the front and the reference Pareto front.\n",
    "    \"\"\"\n",
    "    igd_indicator = IGD(reference_pareto)\n",
    "    return igd_indicator(front)\n",
    "\n",
    "# Settings\n",
    "base_path = \"F:/setup files/Downloads/ResultLastly/\"\n",
    "data_folder = os.path.join(base_path)  # Adjust if your JSON files are in a subfolder\n",
    "nadir_csv_path = os.path.join(base_path, \"nadir_points.csv\")\n",
    "pareto_fronts_path = os.path.join(base_path, \"global_pareto_fronts_last_generation.json\")\n",
    "\n",
    "# Load the nadir points CSV and precomputed Pareto fronts JSON\n",
    "nadir_df = pd.read_csv(nadir_csv_path)\n",
    "with open(pareto_fronts_path, 'r') as pf_file:\n",
    "    pareto_fronts_data = json.load(pf_file)\n",
    "\n",
    "# Define the target generation\n",
    "target_generation = \"100\"\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Get all JSON files in the data folder\n",
    "json_files = glob.glob(os.path.join(data_folder, \"*.json\"))\n",
    "\n",
    "if not json_files:\n",
    "    print(\"No JSON files found in the specified data folder.\")\n",
    "else:\n",
    "    for file_path in json_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "\n",
    "        # Retrieve nadir information corresponding to the file\n",
    "        nadir_row = nadir_df[nadir_df['file'] == file_name]\n",
    "        if nadir_row.empty:\n",
    "            print(f\"Nadir info not found for {file_name}. Skipping.\")\n",
    "            continue\n",
    "        nadir_row = nadir_row.iloc[0]\n",
    "\n",
    "        # Identify objective columns for nadir points\n",
    "        obj_columns = sorted(\n",
    "            [col for col in nadir_df.columns if col.startswith(\"obj_\") and col.endswith(\"_nadir\")],\n",
    "            key=lambda x: int(x.split('_')[1])\n",
    "        )\n",
    "\n",
    "        # Extract the nadir vector\n",
    "        nadir_vector = np.array([nadir_row[col] for col in obj_columns])\n",
    "\n",
    "        # Retrieve the reference Pareto front from the precomputed data for this file\n",
    "        reference_points = pareto_fronts_data.get(file_name, [])\n",
    "        reference_points = np.array(reference_points)\n",
    "\n",
    "        if reference_points.size == 0:\n",
    "            print(f\"No reference Pareto points found for {file_name}. Skipping IGD computation.\")\n",
    "            continue\n",
    "\n",
    "        # Scale the reference Pareto front by the nadir vector\n",
    "        scaled_ref = reference_points / nadir_vector\n",
    "\n",
    "        # Load JSON data from file\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Iterate over each algorithm in the JSON data\n",
    "        for algorithm in data:\n",
    "            if target_generation not in data[algorithm]:\n",
    "                print(f\"Generation {target_generation} not found for {algorithm} in {file_name}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            solutions = data[algorithm][target_generation]\n",
    "            solutions_np = np.array(solutions)\n",
    "\n",
    "            if solutions_np.size == 0:\n",
    "                print(f\"No solutions found for {algorithm} at generation {target_generation} in {file_name}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Scale the solutions using the nadir vector\n",
    "            scaled_solutions = solutions_np / nadir_vector\n",
    "\n",
    "            try:\n",
    "                # Compute IGD on the scaled solutions using the scaled reference Pareto front\n",
    "                igd_value = calculate_igd(scaled_solutions, scaled_ref)\n",
    "            except Exception as e:\n",
    "                print(f\"Error computing IGD for {algorithm} in {file_name}: {e}\")\n",
    "                igd_value = np.nan\n",
    "\n",
    "            # Append the result\n",
    "            results.append({\n",
    "                \"Instance\": file_name,\n",
    "                \"Algorithm\": algorithm,\n",
    "                \"IGD\": igd_value\n",
    "            })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    if df_results.empty:\n",
    "        print(\"No IGD results were computed.\")\n",
    "    else:\n",
    "        # Pivot the DataFrame to have algorithms as columns\n",
    "        pivot_df = df_results.pivot(index=\"Instance\", columns=\"Algorithm\", values=\"IGD\")\n",
    "\n",
    "        # Calculate mean and std for each algorithm\n",
    "        mean_series = pivot_df.mean(axis=0)\n",
    "        std_series = pivot_df.std(axis=0)\n",
    "\n",
    "        # Combine instance-wise IGD and summary\n",
    "        combined_df = pivot_df.copy()\n",
    "        combined_df.loc[\"Mean\"] = mean_series\n",
    "        combined_df.loc[\"Std\"] = std_series\n",
    "\n",
    "        # Optionally, save detailed and summary results to CSV\n",
    "        detailed_csv = os.path.join(base_path, \"igd_pivot.csv\")\n",
    "        combined_df.to_csv(detailed_csv, index_label='Instance')\n",
    "\n",
    "        print(f\"Detailed IGD results saved to {detailed_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
